.. _inference:

Model Evaluation and Inference 
==============================
In this step, we evaluate a set of models on a set of data RDMs, estimate our statistical uncertainty about these evaluations, to draw inferences about the underlying hypotheses. Because different forms of inference require different evaluation schemes, the topics of evaluation and inference are tightly intertwind and are discussed together here. 
We distinguish different tiers of inference complexity, depending on whether we have to do only with fixed models or also with flexible models (which requires cross-validation). Futhermore, we can distinguish between inferences methods that allow generalization over subjects only, or over both subjects and conditions. 

All inference methods are implemented in ``rsatoolbox.inference``. They are named ``eval_*`` and take a list of :ref:`models <model>`
and a :ref:`RDMs object<distances>` of data RDMs as primary inputs and return a results object. Additionally, the string input `method`
allows you to specify which :ref:`RDM comparison measure<comparing>` to use.
This results object contains all information required for further tests including the (co-)variance estimates for model evaluations and potentially the bootstrap samples computed.
The result of the evaluation is stored in the :ref:`results object <result_object>` described below. 

All examples on this page assume that your models are saved in a list of :ref:`model <model>` called ``models`` and your measured data RDMs
are saved as an :ref:`RDMs object<distances>` ``rdms``.
A plot of the results can be generated by using ``rsatoolbox.vis.plot_model_comparison``, which is explained further :ref:`here<model plot>`.

A more interactive introduction on evaluations requiring bootstrap is given by this :doc:`Demo <demo_bootstrap>`.

Types of evaluations
--------------------

Fixed evlaution and inference
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The fastest form inference evaluates a set of models with fixed predictions and estimates the uncertainty based on the variability across
data RDMs. This warrants only generalization to new subjects, not to conditions. Thus, it is formally only applicable to situations where
the used conditions cover the whole set of conditions we are interested in. An example would be RDMs across movements of the 5 fingers.
In this situation, there are no other conditions we want to generalize to.

For this type of inference use ``rsatoolbox.inference.eval_fixed``. This method will evaluate all models and estimate the variances based on
the variance across data RDMs.

Example:

.. code-block:: python

    results = rsatoolbox.inference.eval_fixed(models, rdms, method='corr_cov')
    rsatoolbox.vis.plot_model_comparison(results)

This function takes one additional argument: ``theta``. This argument allows you to set a fixed parameter for flexible models meant to enter this
type of evaluation. It should then be a list of numpy array parameter values in the same order as the models.

Cross-validation across participants / data sets
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When evaluating models with flexible parameters, we need to control for the different complexity of the models. For example, a weighted model with 3 components will fit the data less good than a weighted model with that has those 3 components plus 2 extra components. A good way to evaluate those models is to use leave-one-out cross-validation: The parameters of the rsa model will be fit to N-1 subjects (or data sets) and then evaluated on the Nth subject. 

.. code-block:: python

    train_set, test_set, ceil_set = rsatoolbox.inference.sets_leave_one_out_rdm(rdms_data)
    results_cv = rsatoolbox.inference.crossval(models_flex, rdms_data, train_set, test_set, ceil_set=ceil_set, method='corr')

Bootstrap across participants / data sets 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The variance caused by random sampling of the subjects can also be estimated by using bootstrapping.
This is implemented in ``rsatoolbox.inference.eval_bootstrap_rdm``. In expectation the variance computed by this method is the same as the one
computed by ``eval_fixed``. For this type of analysis it is thus not recommended to use bootstrapping.


Generalization over conditions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There is no direct formula for the variance caused by random sampling of the conditions. Thus, we resort to bootstrapping to estimate this variance.

If we want to generalize only to the population of conditions for the exact subjects measured we can use ``rsatoolbox.inference.eval_bootstrap_pattern``.
This method will perform a bootstrap resampling of the conditions to estimate the uncertainty. This method takes the following inputs additionally
to the ones of ``eval_fixed``: ``N`` sets the number of bootstrap samples to use, ``pattern_descriptor`` is an optional argument to group patterns together.
If a name of a pattern_descriptor is passed, all patterns with an equal entry are included or excluded together.  And ``boot_noise_ceil`` switches
bootstrapping of the noise ceiling on or off. Bootstrapping the noise ceiling (``boot_noise_ceil=true``) is slightly more accurate as average performance over subsampled RDMs
can be different from overall performance, but this takes noticeably more computation time.

Generalization over conditions and subjects
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If we want to generalize over both subjects and conditions/stimuli, we need to apply our novel 2D bootstrap method. This method evaluates the variances
under resampling subjects and conditions both simultaneously and separately and combines these estimates into an estimate of the overall variances
of the estimates. This methods is implemented as ``rsatoolbox.inference.eval_fancy``. The only additional parameter relevant for this computation
is ``rdm_descriptor``, which allows sampling rdms together the same way ``pattern_descriptor`` allows sampling conditions together.
``eval_fancy`` also contains the methodology for performing cross-validation within the bootstrap, which requires a few more inputs
that can be ignored when all inputs are fixed models.


Generalization over conditions and subjects for flexible models 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For evaluating flexible models, that allow some fitting of parameters we use cross-validation to avoid a bias towards more flexible models.
``rsatoolbox`` provides two main functions to do this: ``rsatoolbox.inference.crossval`` which performs a single crossvalidation for a given split
of the data and ``rsatoolbox.inference.eval_fancy`` that performs a crossvalidation within a bootstrap to estimate the uncertainty of this
evaluation as well.



Results objects
---------------

.. _result_object:

A results object contains all information about the analysis that requires substantial computation time. The intended use is to pass this object
directly to visualization functions, test function etc. and do not need to consult the contents directly often. They are accessible for direct access
nonetheless.

The results object contains the following information:

``cv_method``:

    a string specifying the inference method used

``diff_var``:

    variances estimates for all pairwise model differences as a 2D numpy array

``dof``:

    Degrees of freedom for t-tests. The number of levels of the smaller factor generalization is attempted over minus 1.
    For a dataset with 20 stimuli and 10 subjects this would be 9 for generalization over both or subjects only and 19 for generalization over stimuli only.

``evaluations``:

    all evaluation values computed. This is an up to 4 dimensional numpy array (boostrap samples x models x crossvalidation folds (rdm + pattern)).

``method``:

    the RDM similarity measure used for evaluation.

``model_var``:

    variance estimate for each model

``n_model``:

    the number of models evaluated

``noise_ceiling``:

    noise ceiling estimate

``noise_ceil_var``:

    variance estimate for the noise ceiling

``variances``:

    internal covariance matrix over models and the noise ceiling. Usually, ``model_var``, ``diff_var``, and ``noise_ceil_var``, which are derived
    from this matrix are meant for user access.
